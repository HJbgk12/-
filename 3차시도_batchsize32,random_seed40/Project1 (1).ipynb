{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "74bee5b58dad44cd9e3befc57b1af6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_391234b5cf9c424d96a45878ceeb84af",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ea3d584a61a24581a67ea7e3b49efc66",
              "IPY_MODEL_c00c059972954c01b52eb5a9a840e95b",
              "IPY_MODEL_5bb1d631c9fc425e975ad0a6460d6c75"
            ]
          }
        },
        "391234b5cf9c424d96a45878ceeb84af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea3d584a61a24581a67ea7e3b49efc66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e937c36b2175421c9befc4d7e8a280df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_533bdfa1cf254925bac267812c99e451"
          }
        },
        "c00c059972954c01b52eb5a9a840e95b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_705e7ae0d65f4c8f9f48989e99b469dd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a7e7329ae8b492b8bd179bd24f03c2f"
          }
        },
        "5bb1d631c9fc425e975ad0a6460d6c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3146116184bd495f840e9078300818cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:13&lt;00:00, 32.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26f3400f7baf4aee81603891048930b0"
          }
        },
        "e937c36b2175421c9befc4d7e8a280df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "533bdfa1cf254925bac267812c99e451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "705e7ae0d65f4c8f9f48989e99b469dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a7e7329ae8b492b8bd179bd24f03c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3146116184bd495f840e9078300818cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26f3400f7baf4aee81603891048930b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0UgyxxoTq80",
        "outputId": "d308a299-678e-4449-f6dc-a7b53828adb9"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.6)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.24)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.4.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZyPmuV4T6X1",
        "outputId": "edecc5d4-370f-4a2e-88ed-9aa11a5eb6eb"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.11.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us9xGVsSThcE"
      },
      "source": [
        "import os\n",
        "import pdb\n",
        "import wandb\n",
        "import argparse\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "\n",
        "from transformers import (\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    AutoConfig,\n",
        "    AdamW\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WShMRKSXXK3y"
      },
      "source": [
        "def make_id_file(task, tokenizer):\n",
        "    def make_data_strings(file_name):\n",
        "        data_strings = []\n",
        "        with open(os.path.join('sample_data/', file_name), 'r', encoding='utf-8') as f:\n",
        "            id_file_data = [tokenizer.encode(line.lower()) for line in f.readlines()]\n",
        "        for item in id_file_data:\n",
        "            data_strings.append(' '.join([str(k) for k in item]))\n",
        "        return data_strings\n",
        "    \n",
        "    print('it will take some times...')\n",
        "    train_pos = make_data_strings('sentiment.train.1')\n",
        "    train_neg = make_data_strings('sentiment.train.0')\n",
        "    dev_pos = make_data_strings('sentiment.dev.1')\n",
        "    dev_neg = make_data_strings('sentiment.dev.0')\n",
        "\n",
        "    print('make id file finished!')\n",
        "    return train_pos, train_neg, dev_pos, dev_neg"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr_HgZ-AXqKT"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45C67CYtXuKo",
        "outputId": "be46d5bd-7488-449a-d4b1-a7aca5cfa496"
      },
      "source": [
        "train_pos, train_neg, dev_pos, dev_neg = make_id_file('yelp', tokenizer)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it will take some times...\n",
            "make id file finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoKEKH2KZ1H7",
        "outputId": "0e55cbf6-a4ec-4543-a888-e94022dd694f"
      },
      "source": [
        "train_pos[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['101 6581 2833 1012 102',\n",
              " '101 21688 8013 2326 1012 102',\n",
              " '101 2027 2036 2031 3679 19247 1998 3256 6949 2029 2003 2428 2204 1012 102',\n",
              " '101 2009 1005 1055 1037 2204 15174 2098 7570 22974 2063 1012 102',\n",
              " '101 1996 3095 2003 5379 1012 102',\n",
              " '101 2204 3347 2833 1012 102',\n",
              " '101 2204 2326 1012 102',\n",
              " '101 11350 1997 2154 2003 25628 1998 7167 1997 19247 1012 102',\n",
              " '101 2307 2173 2005 6265 2030 3347 27962 1998 5404 1012 102',\n",
              " '101 1996 2047 2846 3504 6429 1012 102']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVxQP81kaNNR"
      },
      "source": [
        "class SentimentDataset(object):\n",
        "    def __init__(self, tokenizer, pos, neg):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "\n",
        "        for pos_sent in pos:\n",
        "            self.data += [self._cast_to_int(pos_sent.strip().split())]\n",
        "            self.label += [[1]]\n",
        "        for neg_sent in neg:\n",
        "            self.data += [self._cast_to_int(neg_sent.strip().split())]\n",
        "            self.label += [[0]]\n",
        "\n",
        "    def _cast_to_int(self, sample):\n",
        "        return [int(word_id) for word_id in sample]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return np.array(sample), np.array(self.label[index])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGqIRJ_XaQHG"
      },
      "source": [
        "train_dataset = SentimentDataset(tokenizer, train_pos, train_neg)\n",
        "dev_dataset = SentimentDataset(tokenizer, dev_pos, dev_neg)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcyHFFkuaSdf",
        "outputId": "670cf582-4ceb-472b-ecbb-804e0b7bfeb6"
      },
      "source": [
        "for i, item in enumerate(train_dataset):\n",
        "    print(item)\n",
        "    if i == 10:\n",
        "        break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([ 101, 6581, 2833, 1012,  102]), array([1]))\n",
            "(array([  101, 21688,  8013,  2326,  1012,   102]), array([1]))\n",
            "(array([  101,  2027,  2036,  2031,  3679, 19247,  1998,  3256,  6949,\n",
            "        2029,  2003,  2428,  2204,  1012,   102]), array([1]))\n",
            "(array([  101,  2009,  1005,  1055,  1037,  2204, 15174,  2098,  7570,\n",
            "       22974,  2063,  1012,   102]), array([1]))\n",
            "(array([ 101, 1996, 3095, 2003, 5379, 1012,  102]), array([1]))\n",
            "(array([ 101, 2204, 3347, 2833, 1012,  102]), array([1]))\n",
            "(array([ 101, 2204, 2326, 1012,  102]), array([1]))\n",
            "(array([  101, 11350,  1997,  2154,  2003, 25628,  1998,  7167,  1997,\n",
            "       19247,  1012,   102]), array([1]))\n",
            "(array([  101,  2307,  2173,  2005,  6265,  2030,  3347, 27962,  1998,\n",
            "        5404,  1012,   102]), array([1]))\n",
            "(array([ 101, 1996, 2047, 2846, 3504, 6429, 1012,  102]), array([1]))\n",
            "(array([ 101, 2023, 2173, 2001, 2200, 2204, 1012,  102]), array([1]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMnPT5enaV27"
      },
      "source": [
        "def collate_fn_sentiment(samples):\n",
        "    input_ids, labels = zip(*samples)\n",
        "    max_len = max(len(input_id) for input_id in input_ids)\n",
        "    sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1] # 데이터 길이순으로 정렬\n",
        "\n",
        "    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n",
        "                             batch_first=True) # 이걸 사용하면 배치사이즈마다의 max_sequance_len을 기준으로 패딩처리를 해줌 : 빨라짐\n",
        "    attention_mask = torch.tensor(\n",
        "        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
        "         sorted_indices])\n",
        "    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
        "    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n",
        "    labels = torch.tensor(np.stack(labels, axis=0)[sorted_indices])\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, position_ids, labels"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNi7itA1aZAN",
        "outputId": "74ccb065-ce73-486b-b17b-1d931bfc53ba"
      },
      "source": [
        "train_batch_size=32\n",
        "eval_batch_size=32\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=train_batch_size,\n",
        "                                           shuffle=True, collate_fn=collate_fn_sentiment,\n",
        "                                           pin_memory=True, num_workers=4)\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=eval_batch_size,\n",
        "                                         shuffle=False, collate_fn=collate_fn_sentiment,\n",
        "                                         num_workers=2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "74bee5b58dad44cd9e3befc57b1af6df",
            "391234b5cf9c424d96a45878ceeb84af",
            "ea3d584a61a24581a67ea7e3b49efc66",
            "c00c059972954c01b52eb5a9a840e95b",
            "5bb1d631c9fc425e975ad0a6460d6c75",
            "e937c36b2175421c9befc4d7e8a280df",
            "533bdfa1cf254925bac267812c99e451",
            "705e7ae0d65f4c8f9f48989e99b469dd",
            "8a7e7329ae8b492b8bd179bd24f03c2f",
            "3146116184bd495f840e9078300818cd",
            "26f3400f7baf4aee81603891048930b0"
          ]
        },
        "id": "2yLu9Y9azbwA",
        "outputId": "5f4ef099-fb18-4f94-8397-292c042779d8"
      },
      "source": [
        "# random seed\n",
        "random_seed=40\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74bee5b58dad44cd9e3befc57b1af6df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GsoMQzUabS0"
      },
      "source": [
        "model.train()\n",
        "learning_rate = 5e-5\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "#*********\n",
        "#t_total = len(train_loader)*train_epoch\n",
        "# 스케줄러 알아볼 것\n",
        "#scheduler = transformer.get_linear_schedule_with_warm_up(optimizer, t_total/10, t_total) # 옵티마이저 설정 "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEwahfDXzqEb"
      },
      "source": [
        "def compute_acc(predictions, target_labels):\n",
        "    return (np.array(predictions) == np.array(target_labels)).mean()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pvymDAAzvaw",
        "outputId": "f3e54682-02ef-4777-feb7-c04090f84d65"
      },
      "source": [
        "train_epoch = 1\n",
        "lowest_valid_loss = 9999.\n",
        "for epoch in range(train_epoch):\n",
        "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "        for iteration, (input_ids, attention_mask, token_type_ids, position_ids, labels) in enumerate(tepoch):\n",
        "            tepoch.set_description(f\"Epoch {epoch}\")\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            position_ids = position_ids.to(device)\n",
        "            labels = labels.to(device, dtype=torch.long)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(input_ids=input_ids,\n",
        "                           attention_mask=attention_mask,\n",
        "                           token_type_ids=token_type_ids,\n",
        "                           position_ids=position_ids,\n",
        "                           labels=labels)\n",
        "\n",
        "            loss = output.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            #scheduler.step() # 스케줄러 설정\n",
        "\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "            if iteration != 0 and iteration % int(len(train_loader) / 5) == 0:\n",
        "                # Evaluate the model five times per epoch\n",
        "                with torch.no_grad():\n",
        "                    model.eval()\n",
        "                    valid_losses = []\n",
        "                    predictions = []\n",
        "                    target_labels = []\n",
        "                    for input_ids, attention_mask, token_type_ids, position_ids, labels in tqdm(dev_loader,\n",
        "                                                                                                desc='Eval',\n",
        "                                                                                                position=1,\n",
        "                                                                                                leave=None):\n",
        "                        input_ids = input_ids.to(device)\n",
        "                        attention_mask = attention_mask.to(device)\n",
        "                        token_type_ids = token_type_ids.to(device)\n",
        "                        position_ids = position_ids.to(device)\n",
        "                        labels = labels.to(device, dtype=torch.long)\n",
        "\n",
        "                        output = model(input_ids=input_ids,\n",
        "                                       attention_mask=attention_mask,\n",
        "                                       token_type_ids=token_type_ids,\n",
        "                                       position_ids=position_ids,\n",
        "                                       labels=labels)\n",
        "\n",
        "                        logits = output.logits\n",
        "                        loss = output.loss\n",
        "                        valid_losses.append(loss.item())\n",
        "\n",
        "                        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
        "                        batch_labels = [int(example) for example in labels]\n",
        "\n",
        "                        predictions += batch_predictions\n",
        "                        target_labels += batch_labels\n",
        "\n",
        "                acc = compute_acc(predictions, target_labels)\n",
        "                valid_loss = sum(valid_losses) / len(valid_losses)\n",
        "                if lowest_valid_loss > valid_loss:\n",
        "                    print('Acc for model which have lower valid loss: ', acc)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13852 [00:00<?, ?batch/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch 0:  20%|█▉        | 2770/13852 [13:30<53:26,  3.46batch/s, loss=0.0688]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:21,  5.73it/s]\u001b[A\n",
            "Eval:   2%|▏         | 3/125 [00:00<00:13,  9.35it/s]\u001b[A\n",
            "Eval:   4%|▍         | 5/125 [00:00<00:10, 11.07it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:10, 11.45it/s]\u001b[A\n",
            "Eval:   7%|▋         | 9/125 [00:00<00:09, 11.67it/s]\u001b[A\n",
            "Eval:   9%|▉         | 11/125 [00:00<00:09, 11.75it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:01<00:09, 12.02it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 15/125 [00:01<00:09, 12.00it/s]\u001b[A\n",
            "Eval:  14%|█▎        | 17/125 [00:01<00:09, 12.00it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:01<00:09, 11.63it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 21/125 [00:01<00:08, 11.68it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 23/125 [00:02<00:08, 11.77it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:02<00:08, 11.83it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 27/125 [00:02<00:08, 11.87it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 29/125 [00:02<00:07, 12.16it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:02<00:07, 12.05it/s]\u001b[A\n",
            "Eval:  26%|██▋       | 33/125 [00:02<00:07, 11.74it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 35/125 [00:03<00:07, 12.04it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:03<00:07, 12.34it/s]\u001b[A\n",
            "Eval:  31%|███       | 39/125 [00:03<00:07, 12.19it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 41/125 [00:03<00:06, 12.08it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:03<00:06, 11.80it/s]\u001b[A\n",
            "Eval:  36%|███▌      | 45/125 [00:03<00:06, 11.86it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 47/125 [00:04<00:06, 11.95it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:04<00:06, 11.58it/s]\u001b[A\n",
            "Eval:  41%|████      | 51/125 [00:04<00:06, 11.48it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 53/125 [00:04<00:06, 11.60it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:04<00:05, 11.77it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 57/125 [00:04<00:05, 12.13it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 59/125 [00:05<00:05, 12.09it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 61/125 [00:05<00:05, 12.10it/s]\u001b[A\n",
            "Eval:  50%|█████     | 63/125 [00:05<00:05, 12.04it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 65/125 [00:05<00:05, 11.74it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 67/125 [00:05<00:05, 11.43it/s]\u001b[A\n",
            "Eval:  55%|█████▌    | 69/125 [00:05<00:05, 11.10it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 71/125 [00:06<00:05, 10.72it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 73/125 [00:06<00:04, 10.66it/s]\u001b[A\n",
            "Eval:  60%|██████    | 75/125 [00:06<00:04, 10.54it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 77/125 [00:06<00:04, 10.05it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:06<00:04, 10.02it/s]\u001b[A\n",
            "Eval:  65%|██████▍   | 81/125 [00:07<00:04, 10.21it/s]\u001b[A\n",
            "Eval:  66%|██████▋   | 83/125 [00:07<00:03, 10.63it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 85/125 [00:07<00:03, 10.56it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 87/125 [00:07<00:03, 10.65it/s]\u001b[A\n",
            "Eval:  71%|███████   | 89/125 [00:07<00:03, 10.38it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 91/125 [00:08<00:03, 10.28it/s]\u001b[A\n",
            "Eval:  74%|███████▍  | 93/125 [00:08<00:03, 10.50it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 95/125 [00:08<00:02, 10.41it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 97/125 [00:08<00:02, 10.69it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 99/125 [00:08<00:02, 10.52it/s]\u001b[A\n",
            "Eval:  81%|████████  | 101/125 [00:08<00:02, 10.65it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 103/125 [00:09<00:02, 10.79it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 105/125 [00:09<00:01, 10.93it/s]\u001b[A\n",
            "Eval:  86%|████████▌ | 107/125 [00:09<00:01, 11.10it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 109/125 [00:09<00:01, 10.70it/s]\u001b[A\n",
            "Eval:  89%|████████▉ | 111/125 [00:09<00:01, 10.33it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 113/125 [00:10<00:01,  9.96it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:10<00:00, 10.21it/s]\u001b[A\n",
            "Eval:  94%|█████████▎| 117/125 [00:10<00:00, 10.38it/s]\u001b[A\n",
            "Eval:  95%|█████████▌| 119/125 [00:10<00:00, 10.64it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:10<00:00, 10.76it/s]\u001b[A\n",
            "Eval:  98%|█████████▊| 123/125 [00:11<00:00, 11.03it/s]\u001b[A\n",
            "Eval: 100%|██████████| 125/125 [00:11<00:00, 10.72it/s]\u001b[A\n",
            "Epoch 0:  20%|██        | 2771/13852 [13:42<11:20:22,  3.68s/batch, loss=0.0688]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  40%|███▉      | 5540/13852 [27:04<40:09,  3.45batch/s, loss=0.0246]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:23,  5.34it/s]\u001b[A\n",
            "Eval:   2%|▏         | 3/125 [00:00<00:13,  9.01it/s]\u001b[A\n",
            "Eval:   4%|▍         | 5/125 [00:00<00:10, 10.96it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:10, 11.33it/s]\u001b[A\n",
            "Eval:   7%|▋         | 9/125 [00:00<00:10, 11.44it/s]\u001b[A\n",
            "Eval:   9%|▉         | 11/125 [00:01<00:09, 11.46it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:01<00:09, 11.85it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 15/125 [00:01<00:09, 11.87it/s]\u001b[A\n",
            "Eval:  14%|█▎        | 17/125 [00:01<00:09, 11.93it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:01<00:09, 11.72it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 21/125 [00:01<00:08, 11.61it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 23/125 [00:02<00:08, 11.66it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:02<00:08, 11.74it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 27/125 [00:02<00:08, 11.87it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 29/125 [00:02<00:07, 12.22it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:02<00:07, 12.14it/s]\u001b[A\n",
            "Eval:  26%|██▋       | 33/125 [00:02<00:07, 11.72it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 35/125 [00:03<00:07, 11.93it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:03<00:07, 12.25it/s]\u001b[A\n",
            "Eval:  31%|███       | 39/125 [00:03<00:07, 12.18it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 41/125 [00:03<00:07, 11.98it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:03<00:06, 11.94it/s]\u001b[A\n",
            "Eval:  36%|███▌      | 45/125 [00:03<00:06, 11.99it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 47/125 [00:04<00:06, 11.99it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:04<00:06, 11.72it/s]\u001b[A\n",
            "Eval:  41%|████      | 51/125 [00:04<00:06, 11.65it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 53/125 [00:04<00:06, 11.62it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:04<00:06, 11.46it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 57/125 [00:04<00:05, 11.79it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 59/125 [00:05<00:05, 11.80it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 61/125 [00:05<00:05, 12.17it/s]\u001b[A\n",
            "Eval:  50%|█████     | 63/125 [00:05<00:05, 12.15it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 65/125 [00:05<00:05, 11.71it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 67/125 [00:05<00:05, 11.44it/s]\u001b[A\n",
            "Eval:  55%|█████▌    | 69/125 [00:05<00:04, 11.27it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 71/125 [00:06<00:04, 11.00it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 73/125 [00:06<00:04, 10.95it/s]\u001b[A\n",
            "Eval:  60%|██████    | 75/125 [00:06<00:04, 10.94it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 77/125 [00:06<00:04, 10.34it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:06<00:04, 10.30it/s]\u001b[A\n",
            "Eval:  65%|██████▍   | 81/125 [00:07<00:04, 10.43it/s]\u001b[A\n",
            "Eval:  66%|██████▋   | 83/125 [00:07<00:03, 10.70it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 85/125 [00:07<00:03, 10.44it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 87/125 [00:07<00:03, 10.42it/s]\u001b[A\n",
            "Eval:  71%|███████   | 89/125 [00:07<00:03, 10.15it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 91/125 [00:08<00:03, 10.16it/s]\u001b[A\n",
            "Eval:  74%|███████▍  | 93/125 [00:08<00:03, 10.38it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 95/125 [00:08<00:02, 10.41it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 97/125 [00:08<00:02, 10.73it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 99/125 [00:08<00:02, 10.58it/s]\u001b[A\n",
            "Eval:  81%|████████  | 101/125 [00:08<00:02, 10.55it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 103/125 [00:09<00:02, 10.61it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 105/125 [00:09<00:01, 10.66it/s]\u001b[A\n",
            "Eval:  86%|████████▌ | 107/125 [00:09<00:01, 10.84it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 109/125 [00:09<00:01, 10.66it/s]\u001b[A\n",
            "Eval:  89%|████████▉ | 111/125 [00:09<00:01, 10.39it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 113/125 [00:10<00:01, 10.10it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:10<00:00, 10.43it/s]\u001b[A\n",
            "Eval:  94%|█████████▎| 117/125 [00:10<00:00, 10.55it/s]\u001b[A\n",
            "Eval:  95%|█████████▌| 119/125 [00:10<00:00, 10.79it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:10<00:00, 10.79it/s]\u001b[A\n",
            "Eval:  98%|█████████▊| 123/125 [00:11<00:00, 10.99it/s]\u001b[A\n",
            "Eval: 100%|██████████| 125/125 [00:11<00:00, 10.83it/s]\u001b[A\n",
            "Epoch 0:  40%|████      | 5541/13852 [27:15<8:31:53,  3.70s/batch, loss=0.0246]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  60%|█████▉    | 8310/13852 [40:38<26:48,  3.45batch/s, loss=0.065]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:21,  5.66it/s]\u001b[A\n",
            "Eval:   2%|▏         | 3/125 [00:00<00:13,  9.12it/s]\u001b[A\n",
            "Eval:   4%|▍         | 5/125 [00:00<00:11, 10.84it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:10, 11.37it/s]\u001b[A\n",
            "Eval:   7%|▋         | 9/125 [00:00<00:10, 11.51it/s]\u001b[A\n",
            "Eval:   9%|▉         | 11/125 [00:01<00:09, 11.50it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:01<00:09, 11.85it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 15/125 [00:01<00:09, 11.83it/s]\u001b[A\n",
            "Eval:  14%|█▎        | 17/125 [00:01<00:09, 11.89it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:01<00:09, 11.67it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 21/125 [00:01<00:08, 11.64it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 23/125 [00:02<00:08, 11.63it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:02<00:08, 11.68it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 27/125 [00:02<00:08, 11.81it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 29/125 [00:02<00:07, 12.11it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:02<00:07, 12.02it/s]\u001b[A\n",
            "Eval:  26%|██▋       | 33/125 [00:02<00:07, 11.68it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 35/125 [00:03<00:07, 11.98it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:03<00:07, 12.20it/s]\u001b[A\n",
            "Eval:  31%|███       | 39/125 [00:03<00:07, 12.15it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 41/125 [00:03<00:07, 11.90it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:03<00:06, 11.84it/s]\u001b[A\n",
            "Eval:  36%|███▌      | 45/125 [00:03<00:06, 11.86it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 47/125 [00:04<00:06, 11.84it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:04<00:06, 11.51it/s]\u001b[A\n",
            "Eval:  41%|████      | 51/125 [00:04<00:06, 11.57it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 53/125 [00:04<00:06, 11.70it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:04<00:06, 11.64it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 57/125 [00:04<00:05, 11.92it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 59/125 [00:05<00:05, 11.83it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 61/125 [00:05<00:05, 12.09it/s]\u001b[A\n",
            "Eval:  50%|█████     | 63/125 [00:05<00:05, 11.96it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 65/125 [00:05<00:05, 11.71it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 67/125 [00:05<00:05, 11.42it/s]\u001b[A\n",
            "Eval:  55%|█████▌    | 69/125 [00:05<00:05, 11.16it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 71/125 [00:06<00:04, 10.82it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 73/125 [00:06<00:04, 10.79it/s]\u001b[A\n",
            "Eval:  60%|██████    | 75/125 [00:06<00:04, 10.89it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 77/125 [00:06<00:04, 10.35it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:06<00:04, 10.34it/s]\u001b[A\n",
            "Eval:  65%|██████▍   | 81/125 [00:07<00:04, 10.53it/s]\u001b[A\n",
            "Eval:  66%|██████▋   | 83/125 [00:07<00:03, 10.84it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 85/125 [00:07<00:03, 10.57it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 87/125 [00:07<00:03, 10.57it/s]\u001b[A\n",
            "Eval:  71%|███████   | 89/125 [00:07<00:03, 10.20it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 91/125 [00:08<00:03, 10.17it/s]\u001b[A\n",
            "Eval:  74%|███████▍  | 93/125 [00:08<00:03, 10.37it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 95/125 [00:08<00:02, 10.21it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 97/125 [00:08<00:02, 10.50it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 99/125 [00:08<00:02, 10.42it/s]\u001b[A\n",
            "Eval:  81%|████████  | 101/125 [00:09<00:02, 10.51it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 103/125 [00:09<00:02, 10.51it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 105/125 [00:09<00:01, 10.59it/s]\u001b[A\n",
            "Eval:  86%|████████▌ | 107/125 [00:09<00:01, 10.86it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 109/125 [00:09<00:01, 10.55it/s]\u001b[A\n",
            "Eval:  89%|████████▉ | 111/125 [00:09<00:01, 10.20it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 113/125 [00:10<00:01,  9.85it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:10<00:00, 10.16it/s]\u001b[A\n",
            "Eval:  94%|█████████▎| 117/125 [00:10<00:00, 10.31it/s]\u001b[A\n",
            "Eval:  95%|█████████▌| 119/125 [00:10<00:00, 10.67it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:10<00:00, 10.69it/s]\u001b[A\n",
            "Eval:  98%|█████████▊| 123/125 [00:11<00:00, 11.01it/s]\u001b[A\n",
            "Eval: 100%|██████████| 125/125 [00:11<00:00, 10.75it/s]\u001b[A\n",
            "Epoch 0:  60%|█████▉    | 8311/13852 [40:49<5:42:02,  3.70s/batch, loss=0.065]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  80%|███████▉  | 11080/13852 [54:12<13:13,  3.49batch/s, loss=0.00363]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:21,  5.73it/s]\u001b[A\n",
            "Eval:   2%|▏         | 2/125 [00:00<00:16,  7.50it/s]\u001b[A\n",
            "Eval:   3%|▎         | 4/125 [00:00<00:12,  9.97it/s]\u001b[A\n",
            "Eval:   5%|▍         | 6/125 [00:00<00:10, 11.24it/s]\u001b[A\n",
            "Eval:   6%|▋         | 8/125 [00:00<00:10, 11.38it/s]\u001b[A\n",
            "Eval:   8%|▊         | 10/125 [00:00<00:10, 11.41it/s]\u001b[A\n",
            "Eval:  10%|▉         | 12/125 [00:01<00:09, 11.48it/s]\u001b[A\n",
            "Eval:  11%|█         | 14/125 [00:01<00:09, 11.89it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 16/125 [00:01<00:09, 11.92it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 18/125 [00:01<00:09, 11.62it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 20/125 [00:01<00:09, 11.56it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 22/125 [00:01<00:09, 11.43it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 24/125 [00:02<00:08, 11.40it/s]\u001b[A\n",
            "Eval:  21%|██        | 26/125 [00:02<00:08, 11.62it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 28/125 [00:02<00:08, 12.08it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 30/125 [00:02<00:07, 12.02it/s]\u001b[A\n",
            "Eval:  26%|██▌       | 32/125 [00:02<00:07, 11.76it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 34/125 [00:02<00:07, 11.98it/s]\u001b[A\n",
            "Eval:  29%|██▉       | 36/125 [00:03<00:07, 12.14it/s]\u001b[A\n",
            "Eval:  30%|███       | 38/125 [00:03<00:07, 12.05it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 40/125 [00:03<00:07, 11.98it/s]\u001b[A\n",
            "Eval:  34%|███▎      | 42/125 [00:03<00:06, 12.00it/s]\u001b[A\n",
            "Eval:  35%|███▌      | 44/125 [00:03<00:06, 11.96it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 46/125 [00:03<00:06, 11.89it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 48/125 [00:04<00:06, 11.58it/s]\u001b[A\n",
            "Eval:  40%|████      | 50/125 [00:04<00:06, 11.62it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 52/125 [00:04<00:06, 11.52it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 54/125 [00:04<00:06, 11.57it/s]\u001b[A\n",
            "Eval:  45%|████▍     | 56/125 [00:04<00:05, 12.02it/s]\u001b[A\n",
            "Eval:  46%|████▋     | 58/125 [00:04<00:05, 12.11it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 60/125 [00:05<00:05, 12.39it/s]\u001b[A\n",
            "Eval:  50%|████▉     | 62/125 [00:05<00:05, 12.09it/s]\u001b[A\n",
            "Eval:  51%|█████     | 64/125 [00:05<00:05, 11.89it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 66/125 [00:05<00:05, 11.42it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 68/125 [00:05<00:05, 11.22it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 70/125 [00:06<00:05, 10.97it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 72/125 [00:06<00:04, 10.95it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 74/125 [00:06<00:04, 10.60it/s]\u001b[A\n",
            "Eval:  61%|██████    | 76/125 [00:06<00:04, 10.23it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 78/125 [00:06<00:04, 10.22it/s]\u001b[A\n",
            "Eval:  64%|██████▍   | 80/125 [00:07<00:04, 10.41it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 82/125 [00:07<00:04, 10.50it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 84/125 [00:07<00:03, 10.58it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 86/125 [00:07<00:03, 10.29it/s]\u001b[A\n",
            "Eval:  70%|███████   | 88/125 [00:07<00:03, 10.31it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 90/125 [00:08<00:03, 10.22it/s]\u001b[A\n",
            "Eval:  74%|███████▎  | 92/125 [00:08<00:03, 10.16it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 94/125 [00:08<00:03, 10.22it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 96/125 [00:08<00:02, 10.44it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 98/125 [00:08<00:02, 10.58it/s]\u001b[A\n",
            "Eval:  80%|████████  | 100/125 [00:08<00:02, 10.63it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 102/125 [00:09<00:02, 10.45it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 104/125 [00:09<00:01, 10.74it/s]\u001b[A\n",
            "Eval:  85%|████████▍ | 106/125 [00:09<00:01, 10.67it/s]\u001b[A\n",
            "Eval:  86%|████████▋ | 108/125 [00:09<00:01, 10.61it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 110/125 [00:09<00:01, 10.65it/s]\u001b[A\n",
            "Eval:  90%|████████▉ | 112/125 [00:10<00:01, 10.04it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 114/125 [00:10<00:01, 10.16it/s]\u001b[A\n",
            "Eval:  93%|█████████▎| 116/125 [00:10<00:00, 10.27it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 118/125 [00:10<00:00, 10.69it/s]\u001b[A\n",
            "Eval:  96%|█████████▌| 120/125 [00:10<00:00, 10.92it/s]\u001b[A\n",
            "Eval:  98%|█████████▊| 122/125 [00:11<00:00, 10.92it/s]\u001b[A\n",
            "Eval:  99%|█████████▉| 124/125 [00:11<00:00, 10.88it/s]\u001b[A\n",
            "Epoch 0:  80%|███████▉  | 11081/13852 [54:24<2:51:07,  3.71s/batch, loss=0.00363]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|█████████▉| 13850/13852 [1:07:49<00:00,  3.61batch/s, loss=0.0828]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:21,  5.66it/s]\u001b[A\n",
            "Eval:   2%|▏         | 2/125 [00:00<00:16,  7.57it/s]\u001b[A\n",
            "Eval:   3%|▎         | 4/125 [00:00<00:12,  9.63it/s]\u001b[A\n",
            "Eval:   5%|▍         | 6/125 [00:00<00:10, 11.08it/s]\u001b[A\n",
            "Eval:   6%|▋         | 8/125 [00:00<00:10, 11.42it/s]\u001b[A\n",
            "Eval:   8%|▊         | 10/125 [00:00<00:09, 11.51it/s]\u001b[A\n",
            "Eval:  10%|▉         | 12/125 [00:01<00:09, 11.48it/s]\u001b[A\n",
            "Eval:  11%|█         | 14/125 [00:01<00:09, 11.92it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 16/125 [00:01<00:09, 11.90it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 18/125 [00:01<00:09, 11.67it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 20/125 [00:01<00:08, 11.76it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 22/125 [00:01<00:08, 11.79it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 24/125 [00:02<00:08, 11.60it/s]\u001b[A\n",
            "Eval:  21%|██        | 26/125 [00:02<00:08, 11.54it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 28/125 [00:02<00:08, 11.97it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 30/125 [00:02<00:07, 11.97it/s]\u001b[A\n",
            "Eval:  26%|██▌       | 32/125 [00:02<00:07, 11.72it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 34/125 [00:02<00:07, 12.08it/s]\u001b[A\n",
            "Eval:  29%|██▉       | 36/125 [00:03<00:07, 12.34it/s]\u001b[A\n",
            "Eval:  30%|███       | 38/125 [00:03<00:07, 12.22it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 40/125 [00:03<00:06, 12.18it/s]\u001b[A\n",
            "Eval:  34%|███▎      | 42/125 [00:03<00:06, 11.89it/s]\u001b[A\n",
            "Eval:  35%|███▌      | 44/125 [00:03<00:06, 11.93it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 46/125 [00:03<00:06, 12.05it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 48/125 [00:04<00:06, 11.63it/s]\u001b[A\n",
            "Eval:  40%|████      | 50/125 [00:04<00:06, 11.48it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 52/125 [00:04<00:06, 11.55it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 54/125 [00:04<00:06, 11.61it/s]\u001b[A\n",
            "Eval:  45%|████▍     | 56/125 [00:04<00:05, 11.93it/s]\u001b[A\n",
            "Eval:  46%|████▋     | 58/125 [00:04<00:05, 11.97it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 60/125 [00:05<00:05, 12.26it/s]\u001b[A\n",
            "Eval:  50%|████▉     | 62/125 [00:05<00:05, 12.03it/s]\u001b[A\n",
            "Eval:  51%|█████     | 64/125 [00:05<00:05, 11.99it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 66/125 [00:05<00:05, 11.67it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 68/125 [00:05<00:05, 11.32it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 70/125 [00:06<00:05, 10.82it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 72/125 [00:06<00:04, 10.79it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 74/125 [00:06<00:04, 10.49it/s]\u001b[A\n",
            "Eval:  61%|██████    | 76/125 [00:06<00:04, 10.12it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 78/125 [00:06<00:04, 10.19it/s]\u001b[A\n",
            "Eval:  64%|██████▍   | 80/125 [00:07<00:04, 10.33it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 82/125 [00:07<00:04, 10.44it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 84/125 [00:07<00:03, 10.60it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 86/125 [00:07<00:03, 10.55it/s]\u001b[A\n",
            "Eval:  70%|███████   | 88/125 [00:07<00:03, 10.63it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 90/125 [00:07<00:03, 10.45it/s]\u001b[A\n",
            "Eval:  74%|███████▎  | 92/125 [00:08<00:03, 10.49it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 94/125 [00:08<00:02, 10.36it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 96/125 [00:08<00:02, 10.48it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 98/125 [00:08<00:02, 10.57it/s]\u001b[A\n",
            "Eval:  80%|████████  | 100/125 [00:08<00:02, 10.70it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 102/125 [00:09<00:02, 10.62it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 104/125 [00:09<00:01, 10.94it/s]\u001b[A\n",
            "Eval:  85%|████████▍ | 106/125 [00:09<00:01, 10.94it/s]\u001b[A\n",
            "Eval:  86%|████████▋ | 108/125 [00:09<00:01, 10.83it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 110/125 [00:09<00:01, 10.85it/s]\u001b[A\n",
            "Eval:  90%|████████▉ | 112/125 [00:10<00:01, 10.11it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 114/125 [00:10<00:01, 10.22it/s]\u001b[A\n",
            "Eval:  93%|█████████▎| 116/125 [00:10<00:00, 10.18it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 118/125 [00:10<00:00, 10.44it/s]\u001b[A\n",
            "Eval:  96%|█████████▌| 120/125 [00:10<00:00, 10.72it/s]\u001b[A\n",
            "Eval:  98%|█████████▊| 122/125 [00:10<00:00, 10.82it/s]\u001b[A\n",
            "Eval:  99%|█████████▉| 124/125 [00:11<00:00, 10.81it/s]\u001b[A\n",
            "Epoch 0: 100%|█████████▉| 13851/13852 [1:08:01<00:03,  3.69s/batch, loss=0.0828]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 13852/13852 [1:08:01<00:00,  3.39batch/s, loss=0.267]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMP3kq3O9mUH"
      },
      "source": [
        "import pandas as pd\n",
        "test_df = pd.read_csv('sample_data/test_no_label.csv')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9H3lMLB93AB"
      },
      "source": [
        "test_dataset = test_df['Id']"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Sa4IAjD9v8P"
      },
      "source": [
        "def make_id_file_test(tokenizer, test_dataset):\n",
        "    data_strings = []\n",
        "    id_file_data = [tokenizer.encode(sent.lower()) for sent in test_dataset]\n",
        "    for item in id_file_data:\n",
        "        data_strings.append(' '.join([str(k) for k in item]))\n",
        "    return data_strings"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTYzme-d9xor"
      },
      "source": [
        "test = make_id_file_test(tokenizer, test_dataset)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoGGLzQl96Ne"
      },
      "source": [
        "test[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mLPHXxk98nk"
      },
      "source": [
        "class SentimentTestDataset(object):\n",
        "    def __init__(self, tokenizer, test):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "\n",
        "        for sent in test:\n",
        "            self.data += [self._cast_to_int(sent.strip().split())]\n",
        "\n",
        "    def _cast_to_int(self, sample):\n",
        "        return [int(word_id) for word_id in sample]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return np.array(sample)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSIk_SHr9-1z"
      },
      "source": [
        "test_dataset = SentimentTestDataset(tokenizer, test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv2SfLwk-A-Y"
      },
      "source": [
        "def collate_fn_sentiment_test(samples):\n",
        "    input_ids = samples\n",
        "    max_len = max(len(input_id) for input_id in input_ids)\n",
        "    sorted_indices = np.array([len(input_id) for input_id in input_ids])\n",
        "\n",
        "    input_ids = pad_sequence([torch.tensor(input_id) for input_id in input_ids],\n",
        "                             batch_first=True)\n",
        "    attention_mask = torch.tensor(\n",
        "        [[1] * len(input_id) + [0] * (max_len - len(input_id)) for input_id in\n",
        "         input_ids])\n",
        "    token_type_ids = torch.tensor([[0] * len(input_id) for input_id in input_ids])\n",
        "    position_ids = torch.tensor([list(range(len(input_id))) for input_id in input_ids])\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, position_ids"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hredtdyq-C83"
      },
      "source": [
        "test_batch_size = 32\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size,\n",
        "                                          shuffle=False, collate_fn=collate_fn_sentiment_test,\n",
        "                                          num_workers=2)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIgV2ZdC-FVl",
        "outputId": "32c89434-fbc9-4b1c-92a6-2e82a5bab0b6"
      },
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    for input_ids, attention_mask, token_type_ids, position_ids in tqdm(test_loader,\n",
        "                                                                        desc='Test',\n",
        "                                                                        position=1,\n",
        "                                                                        leave=None):\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        position_ids = position_ids.to(device)\n",
        "\n",
        "        output = model(input_ids=input_ids,\n",
        "                       attention_mask=attention_mask,\n",
        "                       token_type_ids=token_type_ids,\n",
        "                       position_ids=position_ids)\n",
        "\n",
        "        logits = output.logits\n",
        "        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
        "        predictions += batch_predictions"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Test:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Test:   3%|▎         | 1/32 [00:00<00:05,  5.21it/s]\u001b[A\n",
            "Test:   6%|▋         | 2/32 [00:00<00:04,  6.69it/s]\u001b[A\n",
            "Test:   9%|▉         | 3/32 [00:00<00:03,  7.79it/s]\u001b[A\n",
            "Test:  12%|█▎        | 4/32 [00:00<00:03,  8.15it/s]\u001b[A\n",
            "Test:  19%|█▉        | 6/32 [00:00<00:02,  9.24it/s]\u001b[A\n",
            "Test:  22%|██▏       | 7/32 [00:00<00:02,  9.25it/s]\u001b[A\n",
            "Test:  25%|██▌       | 8/32 [00:00<00:02,  9.41it/s]\u001b[A\n",
            "Test:  31%|███▏      | 10/32 [00:01<00:02, 10.19it/s]\u001b[A\n",
            "Test:  38%|███▊      | 12/32 [00:01<00:01, 10.69it/s]\u001b[A\n",
            "Test:  44%|████▍     | 14/32 [00:01<00:01, 11.06it/s]\u001b[A\n",
            "Test:  50%|█████     | 16/32 [00:01<00:01, 11.43it/s]\u001b[A\n",
            "Test:  56%|█████▋    | 18/32 [00:01<00:01, 11.49it/s]\u001b[A\n",
            "Test:  62%|██████▎   | 20/32 [00:01<00:01, 11.62it/s]\u001b[A\n",
            "Test:  69%|██████▉   | 22/32 [00:02<00:00, 11.73it/s]\u001b[A\n",
            "Test:  75%|███████▌  | 24/32 [00:02<00:00, 11.68it/s]\u001b[A\n",
            "Test:  81%|████████▏ | 26/32 [00:02<00:00, 11.72it/s]\u001b[A\n",
            "Test:  88%|████████▊ | 28/32 [00:02<00:00, 11.54it/s]\u001b[A\n",
            "Test:  94%|█████████▍| 30/32 [00:02<00:00, 11.35it/s]\u001b[A\n",
            "Test: 100%|██████████| 32/32 [00:02<00:00, 12.17it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCeIJ3lv-Hpb"
      },
      "source": [
        "test_df['Category'] = predictions"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quw95D9J-Jy3"
      },
      "source": [
        "test_df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}