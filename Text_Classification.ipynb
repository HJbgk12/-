{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Text Classification_7조_LSTeaM .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odMhPHs0RQjO"
      },
      "source": [
        "# Import requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0Mev35FRbO5",
        "outputId": "e600d5cc-8e4d-42d2-8579-90119467655c"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.4.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.24)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ikwqKt6RrO7",
        "outputId": "d2229ed3-ca97-437c-a18f-c1b95a0e33c0"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-31T02:48:58.348364Z",
          "iopub.execute_input": "2021-10-31T02:48:58.348892Z",
          "iopub.status.idle": "2021-10-31T02:49:04.119374Z",
          "shell.execute_reply.started": "2021-10-31T02:48:58.348855Z",
          "shell.execute_reply": "2021-10-31T02:49:04.118597Z"
        },
        "trusted": true,
        "id": "WAx9S-q3RQjP"
      },
      "source": [
        "import os\n",
        "import pdb\n",
        "import wandb\n",
        "import argparse\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import (\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    AutoConfig,\n",
        "    AdamW,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-31T02:49:17.386396Z",
          "iopub.execute_input": "2021-10-31T02:49:17.386713Z",
          "iopub.status.idle": "2021-10-31T02:49:17.396978Z",
          "shell.execute_reply.started": "2021-10-31T02:49:17.386679Z",
          "shell.execute_reply": "2021-10-31T02:49:17.396215Z"
        },
        "trusted": true,
        "id": "wc5aE2AURQjQ"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: 'checkpoint.pt'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k6rNXvfRQjR"
      },
      "source": [
        "# 1. Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-31T02:49:26.727984Z",
          "iopub.execute_input": "2021-10-31T02:49:26.728254Z",
          "iopub.status.idle": "2021-10-31T02:49:26.735311Z",
          "shell.execute_reply.started": "2021-10-31T02:49:26.728224Z",
          "shell.execute_reply": "2021-10-31T02:49:26.734625Z"
        },
        "trusted": true,
        "id": "HJkFxAf5RQjR"
      },
      "source": [
        "def make_id_file(task, tokenizer):\n",
        "    def make_data_strings(file_name):\n",
        "        data_strings = []\n",
        "        with open(os.path.join('sample_data/', file_name), 'r', encoding='utf-8') as f:\n",
        "            id_file_data = [tokenizer.encode(line.lower()) for line in f.readlines()]\n",
        "        for item in id_file_data:\n",
        "            data_strings.append(' '.join([str(k) for k in item]))\n",
        "        return data_strings\n",
        "    \n",
        "    print('it will take some times...')\n",
        "    train_pos = make_data_strings('sentiment.train.1')\n",
        "    train_neg = make_data_strings('sentiment.train.0')\n",
        "    dev_pos = make_data_strings('sentiment.dev.1')\n",
        "    dev_neg = make_data_strings('sentiment.dev.0')\n",
        "\n",
        "    print('make id file finished!')\n",
        "    return train_pos, train_neg, dev_pos, dev_neg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-31T02:49:29.369906Z",
          "iopub.execute_input": "2021-10-31T02:49:29.370153Z",
          "iopub.status.idle": "2021-10-31T02:49:34.003828Z",
          "shell.execute_reply.started": "2021-10-31T02:49:29.370124Z",
          "shell.execute_reply": "2021-10-31T02:49:34.003122Z"
        },
        "trusted": true,
        "id": "piR8TEuCRQjS"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-31T02:49:37.497611Z",
          "iopub.execute_input": "2021-10-31T02:49:37.498396Z",
          "iopub.status.idle": "2021-10-31T02:52:14.823774Z",
          "shell.execute_reply.started": "2021-10-31T02:49:37.498349Z",
          "shell.execute_reply": "2021-10-31T02:52:14.823084Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyOq4F8zRQjS",
        "outputId": "e506312d-1114-4996-d6ea-18bdfab4aa6c"
      },
      "source": [
        "train_pos, train_neg, dev_pos, dev_neg = make_id_file('yelp', tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it will take some times...\n",
            "make id file finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:23:56.057033Z",
          "iopub.execute_input": "2021-10-30T14:23:56.057413Z",
          "iopub.status.idle": "2021-10-30T14:23:56.066461Z",
          "shell.execute_reply.started": "2021-10-30T14:23:56.057353Z",
          "shell.execute_reply": "2021-10-30T14:23:56.065403Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o56_hTHjRQjT",
        "outputId": "35827a67-ca72-48ae-a345-993a834c31bc"
      },
      "source": [
        "train_pos[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['101 6581 2833 1012 102',\n",
              " '101 21688 8013 2326 1012 102',\n",
              " '101 2027 2036 2031 3679 19247 1998 3256 6949 2029 2003 2428 2204 1012 102',\n",
              " '101 2009 1005 1055 1037 2204 15174 2098 7570 22974 2063 1012 102',\n",
              " '101 1996 3095 2003 5379 1012 102',\n",
              " '101 2204 3347 2833 1012 102',\n",
              " '101 2204 2326 1012 102',\n",
              " '101 11350 1997 2154 2003 25628 1998 7167 1997 19247 1012 102',\n",
              " '101 2307 2173 2005 6265 2030 3347 27962 1998 5404 1012 102',\n",
              " '101 1996 2047 2846 3504 6429 1012 102']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-31T02:52:42.888432Z",
          "iopub.execute_input": "2021-10-31T02:52:42.888689Z",
          "iopub.status.idle": "2021-10-31T02:52:42.898690Z",
          "shell.execute_reply.started": "2021-10-31T02:52:42.888660Z",
          "shell.execute_reply": "2021-10-31T02:52:42.897893Z"
        },
        "trusted": true,
        "id": "nL6vOn91RQjT"
      },
      "source": [
        "class SentimentDataset(object):\n",
        "    def __init__(self, tokenizer, pos, neg):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "\n",
        "        for pos_sent, neg_sent in zip(pos,neg):\n",
        "            self.data += [self._cast_to_int(pos_sent.strip().split())]\n",
        "            self.label += [[1]]\n",
        "            self.data += [self._cast_to_int(neg_sent.strip().split())]\n",
        "            self.label += [[0]]\n",
        "\n",
        "    def _cast_to_int(self, sample):\n",
        "        return [int(word_id) for word_id in sample]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return np.array(sample), np.array(self.label[index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-31T02:52:45.730135Z",
          "iopub.execute_input": "2021-10-31T02:52:45.731022Z",
          "iopub.status.idle": "2021-10-31T02:52:48.718982Z",
          "shell.execute_reply.started": "2021-10-31T02:52:45.730989Z",
          "shell.execute_reply": "2021-10-31T02:52:48.718235Z"
        },
        "trusted": true,
        "id": "WmCRhnnCRQjU"
      },
      "source": [
        "train_dataset = SentimentDataset(tokenizer, train_pos, train_neg)\n",
        "dev_dataset = SentimentDataset(tokenizer, dev_pos, dev_neg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:23:58.649906Z",
          "iopub.execute_input": "2021-10-30T14:23:58.652263Z",
          "iopub.status.idle": "2021-10-30T14:23:58.668367Z",
          "shell.execute_reply.started": "2021-10-30T14:23:58.652216Z",
          "shell.execute_reply": "2021-10-30T14:23:58.667092Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3otLfu9RQjU",
        "outputId": "837beab9-f676-41c4-d77a-08bd20e7f68c"
      },
      "source": [
        "for i, item in enumerate(train_dataset):\n",
        "    print(item)\n",
        "    if i == 10:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([ 101, 6581, 2833, 1012,  102]), array([1]))\n",
            "(array([  101,  1045,  2001, 13718, 13534,  1012,   102]), array([0]))\n",
            "(array([  101, 21688,  8013,  2326,  1012,   102]), array([1]))\n",
            "(array([  101,  2061,  2006,  2000,  1996,  7570, 22974,  2229,  1010,\n",
            "        1996,  3059,  2003,  2236,  2448,  1997,  1996,  4971,  1012,\n",
            "         102]), array([0]))\n",
            "(array([  101,  2027,  2036,  2031,  3679, 19247,  1998,  3256,  6949,\n",
            "        2029,  2003,  2428,  2204,  1012,   102]), array([1]))\n",
            "(array([  101, 10124,  6240,  1998,  1037, 10228,  1997, 29022,  2292,\n",
            "        8525,  3401,  1012,   102]), array([0]))\n",
            "(array([  101,  2009,  1005,  1055,  1037,  2204, 15174,  2098,  7570,\n",
            "       22974,  2063,  1012,   102]), array([1]))\n",
            "(array([  101,  2498,  2428,  2569,  1004,  2025, 11007,  1997,  1996,\n",
            "        1002,  1035, 16371,  2213,  1035,  3976,  6415,  1012,   102]), array([0]))\n",
            "(array([ 101, 1996, 3095, 2003, 5379, 1012,  102]), array([1]))\n",
            "(array([  101,  2117,  1010,  1996, 21475,  7570, 22974,  2063,  1010,\n",
            "        2009,  2003,  2012,  3217, 18436,  1012,   102]), array([0]))\n",
            "(array([ 101, 2204, 3347, 2833, 1012,  102]), array([1]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-31T02:52:53.306699Z",
          "iopub.execute_input": "2021-10-31T02:52:53.307567Z",
          "iopub.status.idle": "2021-10-31T02:52:53.316278Z",
          "shell.execute_reply.started": "2021-10-31T02:52:53.307530Z",
          "shell.execute_reply": "2021-10-31T02:52:53.314500Z"
        },
        "trusted": true,
        "id": "peL7q-f6RQjV"
      },
      "source": [
        "def collate_fn_sentiment(samples):\n",
        "    input_ids, labels = zip(*samples)\n",
        "    max_len = max(len(input_id) for input_id in input_ids)\n",
        "    sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n",
        "\n",
        "    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n",
        "                             batch_first=True)\n",
        "    attention_mask = torch.tensor(\n",
        "        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
        "         sorted_indices])\n",
        "    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
        "    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n",
        "    labels = torch.tensor(np.stack(labels, axis=0)[sorted_indices])\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, position_ids, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-31T02:52:55.658721Z",
          "iopub.execute_input": "2021-10-31T02:52:55.659248Z",
          "iopub.status.idle": "2021-10-31T02:52:55.667250Z",
          "shell.execute_reply.started": "2021-10-31T02:52:55.659210Z",
          "shell.execute_reply": "2021-10-31T02:52:55.666502Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WAnjApKRQjV",
        "outputId": "cb81c5da-594f-4474-cf26-520290ca9433"
      },
      "source": [
        "train_batch_size=128\n",
        "eval_batch_size=128\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=train_batch_size,\n",
        "                                           shuffle=True, collate_fn=collate_fn_sentiment,\n",
        "                                           pin_memory=True, num_workers=4)\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=eval_batch_size,\n",
        "                                         shuffle=False, collate_fn=collate_fn_sentiment,\n",
        "                                         num_workers=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-10-31T02:52:57.804923Z",
          "iopub.execute_input": "2021-10-31T02:52:57.807463Z",
          "iopub.status.idle": "2021-10-31T02:53:16.197699Z",
          "shell.execute_reply.started": "2021-10-31T02:52:57.807352Z",
          "shell.execute_reply": "2021-10-31T02:53:16.197027Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsgQRgf_RQjW",
        "outputId": "e04a9fcc-6f5c-4118-da57-225c09d70f67"
      },
      "source": [
        "# random seed\n",
        "random_seed=42\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-31T02:53:16.199387Z",
          "iopub.execute_input": "2021-10-31T02:53:16.199843Z",
          "iopub.status.idle": "2021-10-31T02:53:16.207598Z",
          "shell.execute_reply.started": "2021-10-31T02:53:16.199805Z",
          "shell.execute_reply": "2021-10-31T02:53:16.206771Z"
        },
        "trusted": true,
        "id": "EwEORvToRQjW"
      },
      "source": [
        "model.train()\n",
        "train_epoch = 20\n",
        "learning_rate = 5e-5\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "t_total = len(train_loader)*train_epoch\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, t_total/10, t_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:24:26.558900Z",
          "iopub.execute_input": "2021-10-30T14:24:26.560948Z",
          "iopub.status.idle": "2021-10-30T14:24:27.558055Z",
          "shell.execute_reply.started": "2021-10-30T14:24:26.560903Z",
          "shell.execute_reply": "2021-10-30T14:24:27.556494Z"
        },
        "trusted": true,
        "id": "LzXJTbMfRQjW"
      },
      "source": [
        "def compute_acc(predictions, target_labels):\n",
        "    return (np.array(predictions) == np.array(target_labels)).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-31T02:48:38.224443Z",
          "iopub.execute_input": "2021-10-31T02:48:38.224723Z",
          "iopub.status.idle": "2021-10-31T02:48:38.264089Z",
          "shell.execute_reply.started": "2021-10-31T02:48:38.224642Z",
          "shell.execute_reply": "2021-10-31T02:48:38.263500Z"
        },
        "trusted": true,
        "id": "YSqD2T_kRQjW"
      },
      "source": [
        "def train_model(model, batch_size, patience, n_epochs):\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    avg_train_losses = []\n",
        "    avg_valid_losses = []\n",
        "    \n",
        "    lowest_valid_loss = 9999.\n",
        "    early_stopping = EarlyStopping(patience = patience, verbose = True)\n",
        "    for epoch in range(n_epochs):\n",
        "        with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "            for iteration, (input_ids, attention_mask, token_type_ids, position_ids, labels) in enumerate(tepoch):\n",
        "                tepoch.set_description(f\"Epoch {epoch}\")\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                token_type_ids = token_type_ids.to(device)\n",
        "                position_ids = position_ids.to(device)\n",
        "                labels = labels.to(device, dtype=torch.long)\n",
        "    \n",
        "                optimizer.zero_grad()\n",
        "    \n",
        "                output = model(input_ids=input_ids,\n",
        "                           attention_mask=attention_mask,\n",
        "                           token_type_ids=token_type_ids,\n",
        "                           position_ids=position_ids,\n",
        "                           labels=labels)\n",
        "\n",
        "                loss = output.loss\n",
        "                loss.backward()\n",
        "    \n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                \n",
        "                train_losses.append(loss.item())\n",
        "    \n",
        "                tepoch.set_postfix(loss=loss.item())\n",
        "                if iteration != 0 and iteration % int(len(train_loader) / 5) == 0:\n",
        "                    # Evaluate the model five times per epoch\n",
        "                    with torch.no_grad():\n",
        "                        model.eval()\n",
        "                        valid_lossesd_losses = []\n",
        "                        predictions = []\n",
        "                        target_labels = []\n",
        "                        for input_ids, attention_mask, token_type_ids, position_ids, labels in tqdm(dev_loader,\n",
        "                                                                                                    desc='Eval',\n",
        "                                                                                                    position=1,\n",
        "                                                                                                    leave=None):\n",
        "                            input_ids = input_ids.to(device)\n",
        "                            attention_mask = attention_mask.to(device)\n",
        "                            token_type_ids = token_type_ids.to(device)\n",
        "                            position_ids = position_ids.to(device)\n",
        "                            labels = labels.to(device, dtype=torch.long)\n",
        "    \n",
        "                            output = model(input_ids=input_ids,\n",
        "                                           attention_mask=attention_mask,\n",
        "                                           token_type_ids=token_type_ids,\n",
        "                                           position_ids=position_ids,\n",
        "                                           labels=labels)\n",
        "    \n",
        "                            logits = output.logits\n",
        "                            loss = output.loss\n",
        "                            valid_losses.append(loss.item())\n",
        "    \n",
        "                            batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
        "                            batch_labels = [int(example) for example in labels]\n",
        "\n",
        "                            predictions += batch_predictions\n",
        "                            target_labels += batch_labels\n",
        "                \n",
        "            \n",
        "\n",
        "                    acc = compute_acc(predictions, target_labels)\n",
        "                    valid_loss = sum(valid_losses) / len(valid_losses)\n",
        "                    if lowest_valid_loss > valid_loss:\n",
        "                        print('Acc for model which have lower valid loss: ', acc)\n",
        "            train_loss = np.average(train_losses)\n",
        "            valid_loss = np.average(valid_losses)\n",
        "            avg_train_losses.append(train_loss)\n",
        "            avg_valid_losses.append(valid_loss)\n",
        "                    \n",
        "            train_losses = []\n",
        "            valid_losses = []\n",
        "                \n",
        "            early_stopping(valid_loss, model)\n",
        "                \n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early Stopping\")\n",
        "                break       \n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "    return model, avg_train_losses, avg_valid_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yg_ldsmRQjX",
        "outputId": "608a7794-d1be-4714-d6a3-16bf48577f76"
      },
      "source": [
        "patience = 10\n",
        "\n",
        "model, train_loss, valid_loss = train_model(model, train_batch_size, patience, train_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2770 [00:00<?, ?batch/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch 0:  20%|██        | 554/2770 [08:35<34:29,  1.07batch/s, loss=0.0863]\n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:14,  2.08it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:12,  2.49it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.73it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:09,  2.83it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.86it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.86it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:08,  2.78it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.80it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.80it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.85it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:03<00:07,  2.85it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:07,  2.83it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.88it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:05<00:06,  2.84it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:06,  2.82it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.89it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:06<00:05,  2.93it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.92it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  2.97it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:07<00:04,  2.97it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.95it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  2.99it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:08<00:03,  2.97it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.96it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.85it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.90it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.90it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.91it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  3.00it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  3.04it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.98it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:10<00:00,  3.73it/s]\u001b[A\n",
            "Epoch 0:  20%|██        | 555/2770 [08:46<2:36:07,  4.23s/batch, loss=0.0863]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.96075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  40%|████      | 1108/2770 [17:20<25:08,  1.10batch/s, loss=0.0797]\n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:14,  2.10it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:11,  2.53it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.76it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:09,  2.82it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.84it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.84it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:09,  2.76it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.77it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.80it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.84it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:03<00:07,  2.88it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:06,  2.86it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.93it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:04<00:06,  2.89it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:05,  2.86it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.88it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:06<00:05,  2.92it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.95it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  2.95it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:07<00:04,  2.96it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.97it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  2.96it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:08<00:03,  2.96it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.96it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.86it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.90it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.88it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.92it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  2.98it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  3.01it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.94it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:10<00:00,  3.68it/s]\u001b[A\n",
            "Epoch 0:  40%|████      | 1109/2770 [17:31<1:56:45,  4.22s/batch, loss=0.0797]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  60%|██████    | 1662/2770 [26:06<17:07,  1.08batch/s, loss=0.0265]\n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:14,  2.10it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:11,  2.53it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.75it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:09,  2.83it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.86it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.86it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:08,  2.80it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.77it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.83it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.85it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:03<00:07,  2.87it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:06,  2.86it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.91it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:04<00:06,  2.87it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:05,  2.86it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.90it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:05<00:05,  2.95it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.93it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  2.97it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:07<00:04,  2.97it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.94it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  3.00it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:08<00:03,  2.98it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.97it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.87it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.88it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.85it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.89it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  2.96it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  2.99it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.96it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:10<00:00,  3.72it/s]\u001b[A\n",
            "Epoch 0:  60%|██████    | 1663/2770 [26:17<1:18:08,  4.24s/batch, loss=0.0265]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  80%|████████  | 2216/2770 [34:54<08:22,  1.10batch/s, loss=0.0362]\n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:14,  2.12it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:11,  2.50it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.75it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:09,  2.84it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.87it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.85it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:09,  2.76it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.78it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.81it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.84it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:03<00:07,  2.88it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:07,  2.86it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.90it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:04<00:06,  2.85it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:05,  2.84it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.91it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:06<00:05,  2.91it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.93it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  2.98it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:07<00:04,  2.97it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.97it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  3.02it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:08<00:03,  2.98it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.97it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.90it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.92it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.91it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.91it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  2.99it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  3.03it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.98it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:10<00:00,  3.73it/s]\u001b[A\n",
            "Epoch 0:  80%|████████  | 2217/2770 [35:05<38:44,  4.20s/batch, loss=0.0362]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 2770/2770 [43:37<00:00,  1.06batch/s, loss=0.0244]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (inf --> 0.085259).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  20%|██        | 554/2770 [08:35<32:50,  1.12batch/s, loss=0.0813]\n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:14,  2.12it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:11,  2.52it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.78it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:09,  2.87it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.87it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.88it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:09,  2.78it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.78it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.81it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.84it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:03<00:07,  2.87it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:07,  2.86it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.90it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:04<00:06,  2.89it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:06,  2.83it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.91it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:05<00:05,  2.93it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.94it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  3.00it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:06<00:03,  3.00it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.97it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  3.01it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:07<00:02,  3.01it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.97it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.90it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.90it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.91it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.91it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  2.95it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  3.01it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.95it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:10<00:00,  3.69it/s]\u001b[A\n",
            "Epoch 1:  20%|██        | 555/2770 [08:46<2:34:42,  4.19s/batch, loss=0.0813]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  40%|████      | 1108/2770 [17:21<25:44,  1.08batch/s, loss=0.1]   \n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:14,  2.16it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:11,  2.55it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.75it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:09,  2.81it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.84it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.84it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:09,  2.74it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.78it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.77it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.84it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:03<00:07,  2.82it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:07,  2.82it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.87it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:05<00:06,  2.82it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:06,  2.80it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.87it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:06<00:05,  2.91it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.91it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  2.96it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:07<00:04,  2.95it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.95it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  2.98it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:08<00:03,  2.95it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.94it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.84it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.89it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.86it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.89it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  2.93it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  2.95it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.90it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:10<00:00,  3.64it/s]\u001b[A\n",
            "Epoch 1:  40%|████      | 1109/2770 [17:33<1:57:10,  4.23s/batch, loss=0.1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  60%|██████    | 1662/2770 [26:10<16:52,  1.09batch/s, loss=0.0451]\n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:14,  2.09it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:12,  2.50it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.71it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:10,  2.79it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.81it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.81it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:09,  2.74it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.77it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.77it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.82it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:03<00:07,  2.83it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:07,  2.83it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.88it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:05<00:06,  2.83it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:06,  2.81it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.86it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:06<00:05,  2.90it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.90it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  2.95it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:07<00:04,  2.92it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.92it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  2.97it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:08<00:03,  2.94it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.93it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.85it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.90it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.86it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.92it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  2.97it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  2.99it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.94it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:10<00:00,  3.69it/s]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1663/2770 [26:21<1:18:28,  4.25s/batch, loss=0.0451]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  80%|████████  | 2216/2770 [34:59<09:12,  1.00batch/s, loss=0.0244]\n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:14,  2.15it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:12,  2.49it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.69it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:10,  2.78it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.81it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.80it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:09,  2.76it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.74it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.78it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.80it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:03<00:07,  2.83it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:07,  2.82it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.87it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:05<00:06,  2.85it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:06,  2.82it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.88it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:06<00:05,  2.94it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.92it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  2.97it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:07<00:04,  2.96it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.94it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  2.98it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:08<00:03,  2.97it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.96it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.86it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.86it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.85it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.89it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  2.93it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  2.95it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.91it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:10<00:00,  3.65it/s]\u001b[A\n",
            "Epoch 1:  80%|████████  | 2217/2770 [35:10<39:35,  4.29s/batch, loss=0.0244]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 2770/2770 [43:48<00:00,  1.05batch/s, loss=0.00466]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (0.085259 --> 0.063852).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  20%|██        | 554/2770 [08:36<34:38,  1.07batch/s, loss=0.00853]\n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:14,  2.07it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:11,  2.51it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.72it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:10,  2.79it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.84it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.83it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:09,  2.76it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.76it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.78it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.83it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:03<00:07,  2.86it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:07,  2.85it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.90it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:05<00:06,  2.82it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:06,  2.82it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.83it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:06<00:05,  2.89it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.86it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  2.91it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:07<00:04,  2.92it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.90it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  2.94it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:08<00:03,  2.91it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.90it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.81it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.86it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.84it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.90it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  2.93it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  2.98it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.94it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:10<00:00,  3.69it/s]\u001b[A\n",
            "Epoch 2:  20%|██        | 555/2770 [08:47<2:37:13,  4.26s/batch, loss=0.00853]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  40%|████      | 1108/2770 [17:26<26:13,  1.06batch/s, loss=0.0145]\n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:14,  2.10it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:12,  2.50it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.73it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:10,  2.80it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.82it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.83it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:09,  2.76it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.79it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.79it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.82it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:03<00:07,  2.85it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:07,  2.84it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.87it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:05<00:06,  2.85it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:06,  2.80it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.85it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:06<00:05,  2.87it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.89it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  2.94it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:07<00:04,  2.92it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.92it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  2.94it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:08<00:03,  2.93it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.92it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.83it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.86it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.84it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.88it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  2.94it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  2.97it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.90it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:11<00:00,  3.63it/s]\u001b[A\n",
            "Epoch 2:  40%|████      | 1109/2770 [17:37<1:57:56,  4.26s/batch, loss=0.0145]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  60%|██████    | 1662/2770 [26:14<16:54,  1.09batch/s, loss=0.007] \n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:14,  2.10it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:12,  2.50it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.71it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:10,  2.78it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.79it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.81it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:09,  2.73it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.73it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.76it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.79it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:04<00:07,  2.82it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:07,  2.82it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.86it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:05<00:06,  2.83it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:06,  2.81it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.87it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:06<00:05,  2.92it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.92it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  2.96it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:07<00:04,  2.95it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.93it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  2.98it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:08<00:03,  2.98it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.93it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.84it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.85it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.85it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.88it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  2.93it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  2.97it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.92it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:10<00:00,  3.64it/s]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1663/2770 [26:25<1:17:58,  4.23s/batch, loss=0.007]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  80%|████████  | 2216/2770 [35:01<08:39,  1.07batch/s, loss=0.0231] \n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:14,  2.12it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:11,  2.50it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.73it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:09,  2.81it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.83it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.83it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:09,  2.76it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.78it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.78it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.84it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:03<00:07,  2.83it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:07,  2.83it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.85it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:05<00:06,  2.83it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:06,  2.80it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.87it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:06<00:05,  2.92it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.92it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  2.97it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:07<00:04,  2.96it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.96it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  2.99it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:08<00:03,  2.97it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.97it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.89it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.93it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.92it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.92it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  2.99it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  3.01it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.93it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:10<00:00,  3.70it/s]\u001b[A\n",
            "Epoch 2:  80%|████████  | 2217/2770 [35:12<39:23,  4.27s/batch, loss=0.0231]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 2770/2770 [43:50<00:00,  1.05batch/s, loss=0.00588]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 1 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  20%|██        | 554/2770 [08:38<34:59,  1.06batch/s, loss=0.0433]\n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:15,  1.97it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:12,  2.46it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.66it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:10,  2.77it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.82it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.80it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:09,  2.75it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.75it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.79it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.81it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:04<00:07,  2.84it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:07,  2.85it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.85it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:05<00:06,  2.84it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:06,  2.78it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.84it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:06<00:05,  2.88it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.86it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  2.91it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:07<00:04,  2.91it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.90it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  2.96it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:08<00:03,  2.94it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.93it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.85it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.88it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.87it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.89it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  2.95it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  2.99it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.95it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:11<00:00,  3.69it/s]\u001b[A\n",
            "Epoch 3:  20%|██        | 555/2770 [08:49<2:38:15,  4.29s/batch, loss=0.0433]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  40%|████      | 1108/2770 [17:26<25:23,  1.09batch/s, loss=0.0213] \n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:14,  2.19it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:11,  2.54it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.70it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:10,  2.78it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.80it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.81it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:09,  2.76it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.76it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.79it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.81it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:03<00:07,  2.84it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:07,  2.82it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.86it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:05<00:06,  2.83it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:06,  2.80it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.85it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:06<00:05,  2.90it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.90it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  2.94it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:07<00:04,  2.95it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.93it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  2.98it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:08<00:03,  2.97it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.94it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.87it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.87it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.88it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.89it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  2.95it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  2.98it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.90it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:10<00:00,  3.63it/s]\u001b[A\n",
            "Epoch 3:  40%|████      | 1109/2770 [17:37<1:56:45,  4.22s/batch, loss=0.0213]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  60%|██████    | 1662/2770 [26:15<17:14,  1.07batch/s, loss=0.00419]\n",
            "Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   3%|▎         | 1/32 [00:00<00:14,  2.15it/s]\u001b[A\n",
            "Eval:   6%|▋         | 2/32 [00:00<00:11,  2.55it/s]\u001b[A\n",
            "Eval:   9%|▉         | 3/32 [00:01<00:10,  2.76it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 4/32 [00:01<00:09,  2.83it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 5/32 [00:01<00:09,  2.86it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 6/32 [00:02<00:09,  2.84it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 7/32 [00:02<00:08,  2.78it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 8/32 [00:02<00:08,  2.76it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 9/32 [00:03<00:08,  2.79it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 10/32 [00:03<00:07,  2.81it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 11/32 [00:03<00:07,  2.83it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 12/32 [00:04<00:07,  2.82it/s]\u001b[A\n",
            "Eval:  41%|████      | 13/32 [00:04<00:06,  2.85it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 14/32 [00:05<00:06,  2.83it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 15/32 [00:05<00:06,  2.81it/s]\u001b[A\n",
            "Eval:  50%|█████     | 16/32 [00:05<00:05,  2.87it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 17/32 [00:06<00:05,  2.92it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 18/32 [00:06<00:04,  2.88it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 19/32 [00:06<00:04,  2.95it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 20/32 [00:07<00:04,  2.93it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 21/32 [00:07<00:03,  2.91it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 22/32 [00:07<00:03,  2.96it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 23/32 [00:08<00:03,  2.93it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 24/32 [00:08<00:02,  2.94it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 25/32 [00:08<00:02,  2.86it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 26/32 [00:09<00:02,  2.87it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 27/32 [00:09<00:01,  2.85it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 28/32 [00:09<00:01,  2.88it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 29/32 [00:10<00:01,  2.94it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 30/32 [00:10<00:00,  2.97it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 31/32 [00:10<00:00,  2.91it/s]\u001b[A\n",
            "Eval: 100%|██████████| 32/32 [00:10<00:00,  3.64it/s]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1663/2770 [26:26<1:18:35,  4.26s/batch, loss=0.00419]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  74%|███████▍  | 2059/2770 [32:36<11:05,  1.07batch/s, loss=0.006]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:24:27.585965Z",
          "iopub.status.idle": "2021-10-30T14:24:27.587387Z",
          "shell.execute_reply.started": "2021-10-30T14:24:27.586999Z",
          "shell.execute_reply": "2021-10-30T14:24:27.587033Z"
        },
        "trusted": true,
        "id": "KWWwjnoHRQjX"
      },
      "source": [
        "import pandas as pd\n",
        "test_df = pd.read_csv('sample_data/test_no_label.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:24:27.589708Z",
          "iopub.status.idle": "2021-10-30T14:24:27.590744Z",
          "shell.execute_reply.started": "2021-10-30T14:24:27.590402Z",
          "shell.execute_reply": "2021-10-30T14:24:27.590455Z"
        },
        "trusted": true,
        "id": "1-pkZUF-RQjX"
      },
      "source": [
        "test_dataset = test_df['Id']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:24:27.593127Z",
          "iopub.status.idle": "2021-10-30T14:24:27.594766Z",
          "shell.execute_reply.started": "2021-10-30T14:24:27.594222Z",
          "shell.execute_reply": "2021-10-30T14:24:27.594256Z"
        },
        "trusted": true,
        "id": "2PTik4VMRQjY"
      },
      "source": [
        "def make_id_file_test(tokenizer, test_dataset):\n",
        "    data_strings = []\n",
        "    id_file_data = [tokenizer.encode(sent.lower()) for sent in test_dataset]\n",
        "    for item in id_file_data:\n",
        "        data_strings.append(' '.join([str(k) for k in item]))\n",
        "    return data_strings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:24:27.596383Z",
          "iopub.status.idle": "2021-10-30T14:24:27.597338Z",
          "shell.execute_reply.started": "2021-10-30T14:24:27.597022Z",
          "shell.execute_reply": "2021-10-30T14:24:27.597056Z"
        },
        "trusted": true,
        "id": "OM7NAcwzRQjY"
      },
      "source": [
        "test = make_id_file_test(tokenizer, test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:24:27.599184Z",
          "iopub.status.idle": "2021-10-30T14:24:27.600437Z",
          "shell.execute_reply.started": "2021-10-30T14:24:27.600120Z",
          "shell.execute_reply": "2021-10-30T14:24:27.600151Z"
        },
        "trusted": true,
        "id": "--A2lgdaRQjY"
      },
      "source": [
        "test[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:24:27.602027Z",
          "iopub.status.idle": "2021-10-30T14:24:27.603358Z",
          "shell.execute_reply.started": "2021-10-30T14:24:27.603043Z",
          "shell.execute_reply": "2021-10-30T14:24:27.603075Z"
        },
        "trusted": true,
        "id": "leXB5ynhRQjY"
      },
      "source": [
        "class SentimentTestDataset(object):\n",
        "    def __init__(self, tokenizer, test):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "\n",
        "        for sent in test:\n",
        "            self.data += [self._cast_to_int(sent.strip().split())]\n",
        "\n",
        "    def _cast_to_int(self, sample):\n",
        "        return [int(word_id) for word_id in sample]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return np.array(sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:24:27.604887Z",
          "iopub.status.idle": "2021-10-30T14:24:27.605814Z",
          "shell.execute_reply.started": "2021-10-30T14:24:27.605480Z",
          "shell.execute_reply": "2021-10-30T14:24:27.605521Z"
        },
        "trusted": true,
        "id": "ioi3golVRQjY"
      },
      "source": [
        "test_dataset = SentimentTestDataset(tokenizer, test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:24:27.607837Z",
          "iopub.status.idle": "2021-10-30T14:24:27.609195Z",
          "shell.execute_reply.started": "2021-10-30T14:24:27.608867Z",
          "shell.execute_reply": "2021-10-30T14:24:27.608900Z"
        },
        "trusted": true,
        "id": "bLgEVOVLRQjY"
      },
      "source": [
        "def collate_fn_sentiment_test(samples):\n",
        "    input_ids = samples\n",
        "    max_len = max(len(input_id) for input_id in input_ids)\n",
        "    sorted_indices = np.array([len(input_id) for input_id in input_ids])\n",
        "\n",
        "    input_ids = pad_sequence([torch.tensor(input_id) for input_id in input_ids],\n",
        "                             batch_first=True)\n",
        "    attention_mask = torch.tensor(\n",
        "        [[1] * len(input_id) + [0] * (max_len - len(input_id)) for input_id in\n",
        "         input_ids])\n",
        "    token_type_ids = torch.tensor([[0] * len(input_id) for input_id in input_ids])\n",
        "    position_ids = torch.tensor([list(range(len(input_id))) for input_id in input_ids])\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, position_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:24:27.610751Z",
          "iopub.status.idle": "2021-10-30T14:24:27.611747Z",
          "shell.execute_reply.started": "2021-10-30T14:24:27.611397Z",
          "shell.execute_reply": "2021-10-30T14:24:27.611450Z"
        },
        "trusted": true,
        "id": "ob7Qhy7DRQjZ"
      },
      "source": [
        "test_batch_size = 32\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size,\n",
        "                                          shuffle=False, collate_fn=collate_fn_sentiment_test,\n",
        "                                          num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:24:27.614058Z",
          "iopub.status.idle": "2021-10-30T14:24:27.616257Z",
          "shell.execute_reply.started": "2021-10-30T14:24:27.615913Z",
          "shell.execute_reply": "2021-10-30T14:24:27.615948Z"
        },
        "trusted": true,
        "id": "YtG6zIv7RQjZ"
      },
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    for input_ids, attention_mask, token_type_ids, position_ids in tqdm(test_loader,\n",
        "                                                                        desc='Test',\n",
        "                                                                        position=1,\n",
        "                                                                        leave=None):\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        position_ids = position_ids.to(device)\n",
        "\n",
        "        output = model(input_ids=input_ids,\n",
        "                       attention_mask=attention_mask,\n",
        "                       token_type_ids=token_type_ids,\n",
        "                       position_ids=position_ids)\n",
        "\n",
        "        logits = output.logits\n",
        "        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
        "        predictions += batch_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:24:27.617937Z",
          "iopub.status.idle": "2021-10-30T14:24:27.618789Z",
          "shell.execute_reply.started": "2021-10-30T14:24:27.618412Z",
          "shell.execute_reply": "2021-10-30T14:24:27.618466Z"
        },
        "trusted": true,
        "id": "8l5WPSDARQjZ"
      },
      "source": [
        "test_df['Category'] = predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-30T14:24:27.620363Z",
          "iopub.status.idle": "2021-10-30T14:24:27.621135Z",
          "shell.execute_reply.started": "2021-10-30T14:24:27.620809Z",
          "shell.execute_reply": "2021-10-30T14:24:27.620842Z"
        },
        "trusted": true,
        "id": "dFQSyqIjRQjZ"
      },
      "source": [
        "test_df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1B28mHJRQjZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}